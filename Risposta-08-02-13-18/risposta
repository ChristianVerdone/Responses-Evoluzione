Ecco la traduzione dello script Python in una recipe MLflow, suddivisa in file separati per ogni step e configurata con `recipe.yaml` e `local.yaml`.

---

### Struttura dei File
```
project/
├── steps/
│   ├── ingest.py
│   ├── split.py
│   ├── transform.py
│   ├── train.py
│   └── validate.py
├── recipe.yaml
└── local.yaml
```

---

### 1. **File `recipe.yaml`**
```yaml
recipe: "wine_classification/v1"
target_col: "is_red"
positive_class: 1
primary_metric: "f1_score"
steps:
  ingest: {{INGEST_CONFIG}}
  split: {{SPLIT_CONFIG}}
  transform: {{TRANSFORM_CONFIG}}
  train: {{TRAIN_CONFIG}}
  validate:
    validation_thresholds:
      f1_score: {{F1_THRESHOLD}}
      precision_score: {{PRECISION_THRESHOLD}}
      recall_score: {{RECALL_THRESHOLD}}
  register:
    allow_non_validated_model: {{ALLOW_NON_VALIDATED_MODEL}}
```

---

### 2. **File `local.yaml`**
```yaml
experiment:
  name: "sklearn_classification_experiment"
  tracking_uri: "sqlite:///metadata/mlflow/mlruns.db"
  artifact_location: "/metadata/mlflow/mlartifacts"

model_registry:
  model_name: "wine_classifier"

INGEST_CONFIG:
  using: csv
  location: ["./data/winequality-white.csv", "./data/winequality-red.csv"]
  loader_method: ingest_data

SPLIT_CONFIG:
  split_ratios: {{SPLIT_RATIOS|default([0.75, 0.125, 0.125])}}

SPLIT_RATIOS: [0.80, 0.10, 0.10]

TRANSFORM_CONFIG:
  transformer_fn: transformer_fn

TRAIN_CONFIG:
  estimator_fn: estimator_fn

F1_THRESHOLD: 0.8
PRECISION_THRESHOLD: 0.75
RECALL_THRESHOLD: 0.7

ALLOW_NON_VALIDATED_MODEL: false
```

---

### 3. **Step di Ingest (`steps/ingest.py`)**
```python
import pandas as pd
import logging

logger = logging.getLogger(__name__)

def ingest_data(file_paths):
    """
    Carica i dati dei vini bianchi e rossi e li unisce.
    """
    logger.info("Caricamento dei dati...")
    data_white = pd.read_csv(file_paths[0], delimiter=';')
    data_red = pd.read_csv(file_paths[1], delimiter=';')

    data_white["is_red"] = 0
    data_red["is_red"] = 1

    data = pd.concat([data_white, data_red], ignore_index=True)
    return data
```

---

### 4. **Step di Split (`steps/split.py`)**
```python
from sklearn.model_selection import train_test_split
import logging

logger = logging.getLogger(__name__)

def split_data(data, split_ratios, target_col):
    """
    Divide il dataset in training, validation e test.
    """
    logger.info("Divisione dei dati...")
    X = data.drop(columns=[target_col])
    y = data[target_col]

    X_train, X_temp, y_train, y_temp = train_test_split(
        X, y, test_size=1 - split_ratios[0], random_state=42
    )

    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp,
        test_size=split_ratios[2] / (split_ratios[1] + split_ratios[2]),
        random_state=42
    )

    return X_train, X_val, X_test, y_train, y_val, y_test
```

---

### 5. **Step di Trasformazione (`steps/transform.py`)**
```python
from sklearn.base import BaseEstimator, TransformerMixin
import pandas as pd

class CustomTransformer(BaseEstimator, TransformerMixin):
    """
    Trasformatore personalizzato per rimuovere valori nulli.
    """
    def fit(self, X, y=None):
        return self

    def transform(self, X):
        X = X.dropna()
        return X

def transformer_fn():
    return CustomTransformer()
```

---

### 6. **Step di Training (`steps/train.py`)**
```python
from sklearn.ensemble import RandomForestClassifier

def estimator_fn(estimator_params=None):
    """
    Definisce il modello RandomForest per l'addestramento.
    """
    if estimator_params is None:
        estimator_params = {}

    model = RandomForestClassifier(**estimator_params)
    return model
```

---

### 7. **Step di Validazione (`steps/validate.py`)**
```python
from sklearn.metrics import f1_score, precision_score, recall_score

def evaluate_model(model, X_test, y_test):
    """
    Valuta le prestazioni del modello e restituisce le metriche.
    """
    y_pred = model.predict(X_test)
    return {
        "f1_score": f1_score(y_test, y_pred),
        "precision_score": precision_score(y_test, y_pred),
        "recall_score": recall_score(y_test, y_pred)
    }
```

---

### Esecuzione della Recipe
Per eseguire la recipe, utilizza il seguente codice in un file separato (ad esempio `run_recipe.py`):
```python
from mlflow.recipes import Recipe

recipe = Recipe(profile="local")
recipe.run()
```

---

### Note Finali
1. **Tipo di Recipe:** La recipe è configurata per una **classification** (poiché il target `is_red` è binario).
2. **Jinja2:** I parametri nel `recipe.yaml` sono referenziati con `{{}}` e definiti nel `local.yaml`.
3. **Output:** I dati intermedi (es. dataset trasformati) e i modelli verranno salvati automaticamente nella cartella `metadata/mlflow`.

Questa struttura garantisce modularità, riproducibilità e tracciabilità completa del workflow con MLflow.