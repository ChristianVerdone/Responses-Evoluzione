Ecco la traduzione dello script Python in una recipe MLflow, strutturata secondo i passaggi e le configurazioni richieste:

---

### Struttura Finale dei File
```
.
├── steps/
│   ├── ingest_step.py
│   ├── split_step.py
│   ├── transform_step.py
│   ├── train_step.py
│   └── evaluate_step.py
├── recipe.yaml
└── local.yaml
```

---

### 1. File `recipe.yaml`
```yaml
recipe: "wine_classifier/v1"
target_col: "is_red"
positive_class: 1
primary_metric: "f1_score"
validation_thresholds:
  f1_score: 0.85
  precision_score: 0.80
  recall_score: 0.80
model_registry:
  model_name: "wine_classifier"
  allow_non_validated_model: {{ALLOW_NON_VALIDATED_MODEL|default(false)}}
steps:
  ingest: {{INGEST_CONFIG}}
  split: {{SPLIT_CONFIG}}
  transform: {{TRANSFORM_CONFIG}}
  train: {{TRAIN_CONFIG}}
  evaluate: {{EVALUATE_CONFIG}}
```

---

### 2. File `local.yaml`
```yaml
experiment:
  name: "sklearn_classification_experiment"
  tracking_uri: "sqlite:///metadata/mlflow/mlruns.db"
  artifact_location: "/metadata/mlflow/mlartifacts"

INGEST_CONFIG:
  using: csv
  location: ["./data/winequality-white.csv", "./data/winequality-red.csv"]
  delimiter: ";"
  loader_method: "ingest_data"

SPLIT_CONFIG:
  split_ratios: [0.80, 0.10, 0.10]

TRANSFORM_CONFIG:
  transform_method: "transform_data"

TRAIN_CONFIG:
  estimator_params:
    n_estimators: 100
    random_state: 42

EVALUATE_CONFIG:
  metrics: ["f1_score", "precision_score", "recall_score"]

ALLOW_NON_VALIDATED_MODEL: false
```

---

### 3. File degli Step Separati

#### **`steps/ingest_step.py`**
```python
import pandas as pd
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def ingest_data(file_paths, delimiter=";"):
    """Carica e combina i dataset dei vini bianco e rosso."""
    data_white = pd.read_csv(file_paths[0], delimiter=delimiter)
    data_red = pd.read_csv(file_paths[1], delimiter=delimiter)

    data_white["is_red"] = 0
    data_red["is_red"] = 1

    data = pd.concat([data_white, data_red], ignore_index=True)
    logger.info(f"Dati caricati. Dimensioni totali: {data.shape}")
    return data
```

#### **`steps/split_step.py`**
```python
from sklearn.model_selection import train_test_split
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def split_data(X, y, split_ratios):
    """Divide i dati in training, validation e test."""
    X_train, X_temp, y_train, y_temp = train_test_split(
        X, y, test_size=1 - split_ratios[0], random_state=42
    )
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp,
        test_size=split_ratios[2] / (split_ratios[1] + split_ratios[2]),
        random_state=42
    )
    logger.info(f"Split completato: Train={len(X_train)}, Val={len(X_val)}, Test={len(X_test)}")
    return X_train, X_val, X_test, y_train, y_val, y_test
```

#### **`steps/transform_step.py`**
```python
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def transform_data(data):
    """Esegue la pulizia dei dati (rimozione valori nulli)."""
    data = data.dropna()
    logger.info(f"Dati trasformati. Dimensioni dopo pulizia: {data.shape}")
    return data
```

#### **`steps/train_step.py`**
```python
from sklearn.ensemble import RandomForestClassifier
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def estimator_fn(estimator_params=None):
    """Crea un'istanza di RandomForestClassifier."""
    if estimator_params is None:
        estimator_params = {}
    model = RandomForestClassifier(**estimator_params)
    logger.info("Modello RandomForest inizializzato")
    return model
```

#### **`steps/evaluate_step.py`**
```python
from sklearn.metrics import f1_score, precision_score, recall_score
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def evaluate_model(model, X_test, y_test):
    """Calcola le metriche di valutazione."""
    y_pred = model.predict(X_test)
    return {
        "f1_score": f1_score(y_test, y_pred),
        "precision_score": precision_score(y_test, y_pred),
        "recall_score": recall_score(y_test, y_pred)
    }
```

---

### 4. Esecuzione della Recipe
Per eseguire la recipe, utilizzare il comando MLflow:
```bash
mlflow recipes run --recipe wine_classifier
```

---

### Note Importanti:
1. **Tipo di Recipe**: Il target `is_red` è binario (0/1), quindi la recipe è di **classification**.
2. **Jinja2 Integration**: I placeholder come `{{INGEST_CONFIG}}` nel `recipe.yaml` fanno riferimento alle chiavi nel `local.yaml`.
3. **Parametri Custom**:
   - `delimiter: ";"` gestisce i file CSV con separatore personalizzato.
   - `allow_non_validated_model` blocca la registrazione di modelli sotto le soglie.
4. **Logging Automatico**: MLflow traccia automaticamente parametri/metriche durante l'esecuzione della recipe.