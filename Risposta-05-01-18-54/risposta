Ecco la traduzione dello script Python in una recipe di MLflow, con i vari step separati e i file `recipe.yaml` e `local.yaml` configurati come richiesto.

### Step 1: Script di Ingestione dei Dati (`ingest.py`)
```python
import pandas as pd
import logging

# Configura il logger
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

def ingest_data(file_paths):
    """
    Carica i dati dei vini bianco e rosso con il delimitatore corretto.
    
    :param file_paths: Lista dei percorsi dei file CSV
    :return: DataFrame contenente i dati uniti
    """
    data_white = pd.read_csv(file_paths[0], delimiter=';')
    data_red = pd.read_csv(file_paths[1], delimiter=';')

    data_white["is_red"] = 0
    data_red["is_red"] = 1

    data = pd.concat([data_white, data_red], ignore_index=True)
    return data

if __name__ == "__main__":
    file_paths = ["./data/winequality-white.csv", "./data/winequality-red.csv"]
    data = ingest_data(file_paths)
    data.to_csv("./data/ingested_data.csv", index=False)
```

### Step 2: Script di Trasformazione dei Dati (`transform.py`)
```python
import pandas as pd
import logging

# Configura il logger
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

def transform_data(data):
    """
    Esegue trasformazioni personalizzate sui dati.
    
    :param data: DataFrame contenente i dati da trasformare
    :return: DataFrame trasformato
    """
    data = data.dropna()
    return data

if __name__ == "__main__":
    data = pd.read_csv("./data/ingested_data.csv")
    transformed_data = transform_data(data)
    transformed_data.to_csv("./data/transformed_data.csv", index=False)
```

### Step 3: Script di Divisione dei Dati (`split.py`)
```python
import pandas as pd
from sklearn.model_selection import train_test_split
import logging

# Configura il logger
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

def split_data(data, split_ratios):
    """
    Divide i dati nei set di training, validation e test.
    
    :param data: DataFrame contenente i dati da dividere
    :param split_ratios: Lista di tre valori che rappresentano le proporzioni per training, validation e test
    :return: Tuple contenente i DataFrame per training, validation e test
    """
    target_col = "is_red"
    X = data.drop(columns=[target_col])
    y = data[target_col]

    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=1 - split_ratios[0], random_state=42)
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp,
                                                    test_size=split_ratios[2] / (split_ratios[1] + split_ratios[2]),
                                                    random_state=42)
    return X_train, X_val, X_test, y_train, y_val, y_test

if __name__ == "__main__":
    data = pd.read_csv("./data/transformed_data.csv")
    split_ratios = [0.80, 0.10, 0.10]
    X_train, X_val, X_test, y_train, y_val, y_test = split_data(data, split_ratios)

    X_train.to_csv("./data/X_train.csv", index=False)
    X_val.to_csv("./data/X_val.csv", index=False)
    X_test.to_csv("./data/X_test.csv", index=False)
    y_train.to_csv("./data/y_train.csv", index=False)
    y_val.to_csv("./data/y_val.csv", index=False)
    y_test.to_csv("./data/y_test.csv", index=False)
```

### Step 4: Script di Addestramento del Modello (`train.py`)
```python
import pandas as pd
import mlflow
import mlflow.sklearn
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score, precision_score, recall_score
import logging

# Configura il logger
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

def train_model(X_train, y_train):
    """
    Addestra un modello di RandomForestClassifier.
    
    :param X_train: DataFrame contenente le caratteristiche di training
    :param y_train: Series contenente i target di training
    :return: Modello addestrato
    """
    model = RandomForestClassifier()
    model.fit(X_train, y_train)
    return model

def evaluate_model(model, X_test, y_test):
    """
    Valuta il modello addestrato.
    
    :param model: Modello addestrato
    :param X_test: DataFrame contenente le caratteristiche di test
    :param y_test: Series contenente i target di test
    :return: Tuple contenente f1_score, precision_score e recall_score
    """
    y_pred = model.predict(X_test)
    f1 = f1_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    return f1, precision, recall

if __name__ == "__main__":
    mlflow.set_tracking_uri("sqlite:///metadata/mlflow/mlruns.db")
    mlflow.set_experiment("sklearn_classification_experiment")

    X_train = pd.read_csv("./data/X_train.csv")
    y_train = pd.read_csv("./data/y_train.csv").squeeze()
    X_test = pd.read_csv("./data/X_test.csv")
    y_test = pd.read_csv("./data/y_test.csv").squeeze()

    with mlflow.start_run():
        model = train_model(X_train, y_train)
        mlflow.sklearn.log_model(model, "model")

        f1, precision, recall = evaluate_model(model, X_test, y_test)
        mlflow.log_param("model_type", "RandomForest")
        mlflow.log_metric("f1_score", f1)
        mlflow.log_metric("precision_score", precision)
        mlflow.log_metric("recall_score", recall)

        print("F1 Score:", f1)
        print("Precision Score:", precision)
        print("Recall Score:", recall)
```

### File `recipe.yaml`
```yaml
recipe: "classification/v1"
target_col: "is_red"
positive_class: 1
primary_metric: "f1_score"
steps:
  ingest: {{INGEST_CONFIG}}
  transform: {{TRANSFORM_CONFIG}}
  split: {{SPLIT_CONFIG}}
  train: {{TRAIN_CONFIG}}
  evaluate: {{EVALUATE_CONFIG}}

INGEST_CONFIG:
  using: csv
  location: ["./data/winequality-white.csv", "./data/winequality-red.csv"]
  loader_method: ingest_data

TRANSFORM_CONFIG:
  params: {}

SPLIT_CONFIG:
  split_ratios: [0.80, 0.10, 0.10]

TRAIN_CONFIG:
  estimator_params:
    max_iter: 1000
    tol: 1e-3

EVALUATE_CONFIG:
  validation_thresholds:
    f1_score: 0.75
    precision_score: 0.70
    recall_score: 0.70
  allow_non_validated_model: false
```

### File `local.yaml`
```yaml
experiment:
  name: "sklearn_classification_experiment"
  tracking_uri: "sqlite:///metadata/mlflow/mlruns.db"
  artifact_location: "/metadata/mlflow/mlartifacts"

model_registry:
  model_name: "wine_classifier"

INGEST_CONFIG:
  using: csv
  location: ["./data/winequality-white.csv", "./data/winequality-red.csv"]
  loader_method: ingest_data

SPLIT_CONFIG:
  split_ratios: [0.80, 0.10, 0.10]

TRAIN_CONFIG:
  estimator_params:
    max_iter: 1000
    tol: 1e-3

EVALUATE_CONFIG:
  validation_thresholds:
    f1_score: 0.75
    precision_score: 0.70
    recall_score: 0.70
  allow_non_validated_model: false
```

Con questi file, dovresti essere in grado di eseguire la tua pipeline di machine learning utilizzando MLflow. Se hai bisogno di ulteriori dettagli o chiarimenti, fammi sapere!