Ecco come tradurre lo script Python fornito in una recipe di MLflow, separando i vari step e creando i file `recipe.yaml` e `local.yaml`.

### Script Python per lo Step di Ingest
```python
import logging
import pandas as pd

# Configura il logger
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

def ingest_data(file_paths):
    """
    Carica i dati dei vini bianco e rosso con il delimitatore corretto.

    :param file_paths: Lista dei percorsi dei file CSV
    :return: DataFrame contenente i dati uniti
    """
    logger.info(f"Caricamento dei dati dai file: {file_paths}")

    data_white = pd.read_csv(file_paths[0], delimiter=';')
    data_red = pd.read_csv(file_paths[1], delimiter=';')

    data_white["is_red"] = 0
    data_red["is_red"] = 1

    data = pd.concat([data_white, data_red], ignore_index=True)
    return data

# Esempio di utilizzo della funzione
if __name__ == "__main__":
    file_paths = ["./data/winequality-white.csv", "./data/winequality-red.csv"]
    data = ingest_data(file_paths)
    data.to_csv("/data/ingested_data.csv", index=False)
```

### Script Python per lo Step di Split
```python
import logging
import pandas as pd
from sklearn.model_selection import train_test_split

# Configura il logger
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

def split_data(data, target_col, split_ratios):
    """
    Divide il dataset nei set di training, validation e test.

    :param data: DataFrame contenente i dati
    :param target_col: Nome della colonna target
    :param split_ratios: Lista di tre valori che rappresentano le proporzioni per training, validation e test
    :return: Tuple contenente i DataFrame per training, validation e test
    """
    logger.info(f"Divisione del dataset con proporzioni: {split_ratios}")

    X = data.drop(columns=[target_col])
    y = data[target_col]

    train_size, val_size = split_ratios[0], split_ratios[1]
    test_size = 1 - train_size - val_size

    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=(val_size + test_size), random_state=42)
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=(test_size / (val_size + test_size)), random_state=42)

    return X_train, X_val, X_test, y_train, y_val, y_test

# Esempio di utilizzo della funzione
if __name__ == "__main__":
    data = pd.read_csv("/data/ingested_data.csv")
    target_col = "is_red"
    split_ratios = [0.80, 0.10, 0.10]
    X_train, X_val, X_test, y_train, y_val, y_test = split_data(data, target_col, split_ratios)
    X_train.to_csv("/data/X_train.csv", index=False)
    X_val.to_csv("/data/X_val.csv", index=False)
    X_test.to_csv("/data/X_test.csv", index=False)
    y_train.to_csv("/data/y_train.csv", index=False)
    y_val.to_csv("/data/y_val.csv", index=False)
    y_test.to_csv("/data/y_test.csv", index=False)
```

### Script Python per lo Step di Trasformazione
```python
import logging
import pandas as pd

# Configura il logger
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

def transform_data(data):
    """
    Trasforma i dati rimuovendo i valori nulli.

    :param data: DataFrame contenente i dati
    :return: DataFrame contenente i dati trasformati
    """
    logger.info("Trasformazione dei dati: rimozione dei valori nulli")
    data = data.dropna()
    return data

# Esempio di utilizzo della funzione
if __name__ == "__main__":
    X_train = pd.read_csv("/data/X_train.csv")
    X_val = pd.read_csv("/data/X_val.csv")
    X_test = pd.read_csv("/data/X_test.csv")

    X_train = transform_data(X_train)
    X_val = transform_data(X_val)
    X_test = transform_data(X_test)

    X_train.to_csv("/data/X_train_transformed.csv", index=False)
    X_val.to_csv("/data/X_val_transformed.csv", index=False)
    X_test.to_csv("/data/X_test_transformed.csv", index=False)
```

### Script Python per lo Step di Training
```python
import logging
import pandas as pd
import mlflow
import mlflow.sklearn
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score, precision_score, recall_score

# Configura il logger
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

def train_model(X_train, y_train):
    """
    Addestra un modello RandomForestClassifier.

    :param X_train: DataFrame contenente le caratteristiche di addestramento
    :param y_train: Series contenente il target di addestramento
    :return: Modello addestrato
    """
    logger.info("Addestramento del modello RandomForestClassifier")
    model = RandomForestClassifier()
    model.fit(X_train, y_train)
    return model

def evaluate_model(model, X_test, y_test):
    """
    Valuta il modello addestrato.

    :param model: Modello addestrato
    :param X_test: DataFrame contenente le caratteristiche di test
    :param y_test: Series contenente il target di test
    :return: Tuple contenente f1_score, precision_score e recall_score
    """
    logger.info("Valutazione del modello")
    y_pred = model.predict(X_test)
    f1 = f1_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    return f1, precision, recall

# Esempio di utilizzo della funzione
if __name__ == "__main__":
    mlflow.set_tracking_uri("sqlite:///metadata/mlflow/mlruns.db")
    mlflow.set_experiment("sklearn_classification_experiment")

    X_train = pd.read_csv("/data/X_train_transformed.csv")
    y_train = pd.read_csv("/data/y_train.csv").squeeze()
    X_test = pd.read_csv("/data/X_test_transformed.csv")
    y_test = pd.read_csv("/data/y_test.csv").squeeze()

    with mlflow.start_run():
        model = train_model(X_train, y_train)
        mlflow.sklearn.log_model(model, "model")

        f1, precision, recall = evaluate_model(model, X_test, y_test)

        mlflow.log_param("model_type", "RandomForest")
        mlflow.log_metric("f1_score", f1)
        mlflow.log_metric("precision_score", precision)
        mlflow.log_metric("recall_score", recall)

        print("F1 Score:", f1)
        print("Precision Score:", precision)
        print("Recall Score:", recall)
```

### File `recipe.yaml`
```yaml
recipe: "classification/v1"
target_col: "is_red"
positive_class: 1
primary_metric: "f1_score"
steps:
  ingest:
    using: csv
    location: {{INGEST_CONFIG.location}}
    loader_method: ingest_data
  split:
    split_ratios: {{SPLIT_RATIOS|default([0.75, 0.125, 0.125])}}
  transform:
    transform_params: {{TRANSFORM_PARAMS|default({})}}
  train:
    estimator_params: {{ESTIMATOR_PARAMS|default({})}}
  evaluate:
    thresholds:
      f1_score: 0.75
      precision_score: 0.75
      recall_score: 0.75
    allow_non_validated_model: false
```

### File `local.yaml`
```yaml
experiment:
  name: "sklearn_classification_experiment"
  tracking_uri: "sqlite:///metadata/mlflow/mlruns.db"
  artifact_location: "/metadata/mlflow/mlartifacts"

model_registry:
  model_name: "wine_classifier"

SPLIT_RATIOS: [0.80, 0.10, 0.10]
TRANSFORM_PARAMS: {}
ESTIMATOR_PARAMS:
  n_estimators: 100
  max_depth: 10
  random_state: 42
INGEST_CONFIG:
  location: ["./data/winequality-white.csv", "./data/winequality-red.csv"]
```

### Note
- **Script Separati**: Ogni step (ingest, split, transform, train) Ã¨ separato in script distinti.
- **File YAML**: `recipe.yaml` e `local.yaml` sono configurati per specificare i dettagli dell'esperimento e del modello.
- **Dipendenze**: Assicurati di avere `pandas`, `scikit-learn`, e `mlflow` installati nel tuo ambiente (`pip install pandas scikit-learn mlflow`).

Se hai bisogno di ulteriori chiarimenti o assistenza, fammi sapere!